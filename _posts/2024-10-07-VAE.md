---
layout: post
title: Image construction experiment
date: 2024-08-30 16:15:09
description: 
tags: formatting images
categories: encoding method
tabs: true
related_posts: false
toc: 
  sidebar: left
---


# AE

Before talking about VAE, first talk about AE model. AE model a

# VAE

VAE is a type of image construction algorithm, including encoder and decoder. Encoder receives input image and produce mean vectors and deviation vectors that define a series of independent normal distributions. Then the model will draw a sample from the distributions and use decoder to produce an image.

I implemented a simple version of VAE, using CNN as the encoder and decoder

The number of dimension in mean and deviation vectors has a significant impact on the quality of image generation. 

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/image construction/VAE_4_2.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/image construction/VAE_4_4.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/image construction/VAE_4_10.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    From left to right, the dimension in mean vector and deviation vectors is 2, 4, 10
</div>

As the latent space dimention increases, the quality of produced image significantly improves. 

However, when we use images with more details to train the model, such as CIFAR10, the model can't reconstruct the original images. The reconstructed images are instead very blurry.
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/image construction/VAE_cifar10.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/image construction/VAE_cifar101.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/image construction/VAE_cifar102.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    I try to improve performance of VAE on CIFAR10 by only training on 200, 100, 25 images. However, the generated images are very blurry.
</div>

As I change the size of train dataset, there's an interesting phenomenon regarding image generation.

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/image construction/VAE_cifar103.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/image construction/VAE_cifar105.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/image construction/VAE_cifar104.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    The model is trained on a single batch of 2 images. The left image is the generated image.
</div>

We can see that the generated image is like taking the average of the images in a batch. This is probably 
because when doing back propagation, the model is doing propagation on all images and takes the average of the gradient. Thus, the final image will resemble all the images in the batch.

# Causes

As I checked from website, I got to know a phenomenon called posterior collpase. Posterior collapse is when signal from input x to posterior parameters is either too weak or too noisy, and as a result, decoder starts ignoring z samples drawn from the distribution by encoder. 

A more evident phenomenon is when the decoder generates an image regardless of the input. Thus, I tested some images on VAE to see whether they produce the same image despite different inputs.

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/image construction/39211730226621_.pic.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/image construction/39221730226633_.pic.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/image construction/39231730226639_.pic.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/image construction/39241730226646_.pic.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/image construction/39251730226653_.pic.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

The second and fourth images are generated based on latent variable by the first and third images. The the most right one is generated based on a random noise. We can see that the generated images are nearly the same, which satisfies the symptoms of posterior collapse. 

Next, I try to figure out the cause of such phenomenon. I first check latent variables z for first and third images, making sure that they are not 0 and different. However, they are not nearly 0 and are different from each other, meaning that the problem probably lies on the decoder instead of encoder. 

I then changed the decoder, adding more linear layers and hoping it can learn more about latent variable. However, it doesn't work and the generated images are still very blurry and the same for any latent variable z. So, it's most likely not the fault of decoder.

Later, I examine the loss function which has two parts, reconstruction loss and KL loss. econstruction loss measures whether the generated image matches the original image. KL loss measures whether distribution of latent varaible matches standard Gaussian distribution. During training session, I found out that reconstruction loss is usually 0.2 and remains the same during the process. The KL loss is usually a few hundred initially and then rapidly decreasing to 1 or 2. This stark contrast between reconstruction loss and KL loss is possibly the reason why the model neglects image reconstruction.

Threfore, I heavily penalized reconstruction loss, multiplying it by 6000. Below are the result after penalizing reconstruction:

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/image construction/39401730233614_.pic.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/image construction/39411730233637_.pic.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/image construction/39421730233650_.pic.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/image construction/39431730233659_.pic.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

Finally, the model is able to generate discernable image based on the original image, but the generated image is still a bit blurry. 

