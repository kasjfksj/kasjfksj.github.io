<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> LoRA - a potential parameter efficient fine-tuning method for large models | Xiaoyang Li </title> <meta name="author" content="Xiaoyang Li"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kasjfksj.github.io/blog/2024/LoRAa/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Xiaoyang</span> Li </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">LoRA - a potential parameter efficient fine-tuning method for large models</h1> <p class="post-meta"> Created in August 13, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/category/ai"> <i class="fa-solid fa-tag fa-sm"></i> AI</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="background">Background</h2> <p>Imagine you are a researcher testing out language models such as Small T5 or LSTM and you have decent but not great amouont of GPUs. You want to finetune the model to test their performances on a few datasets. You train your model on the datasets and get the results. You are satisfied.</p> <p>But what if there are hundreds of datasets you want to test and not only that, you want to test out current LLM like LLama and Mistral that have billions of parameters. It’s impossible to train on your limited GPU since there are so many parameters that need to be updated through back propogation. You need a way to minimize the number of parameter updates without costing too much computation resources. This is where LoRA comes to play.</p> <h2 id="gradient-descent">Gradient Descent</h2> <p>Every AI model, LLM or CNN, is basically a mathematical function that’s based on some parameters \(\theta\). Parameters are usually weight matrix that multiply with input matrix. For most datasets, we have inputs \(X\) and targets \(Y\). For instance, the input can be a sentence and the output is 0 and 1 where 0 represents negative sentiment and 1 represents positive sentiment. We give the model input \(x \ \ and \ \ x \in X\), and it outputs \(\textit{f}(x, \theta)\). However, we wish that the output will be the target \(y \ \ and \ \ y \in Y\). We use gradient descent to minimize the distance between outcomes and desired outcomes.</p> \[W_t = W_{t-1} + \Delta W \ \ where\ \ W\ \ is \ \ parameter \ \ and \ \ t \ \ is \ \ each \ \ iteration\] <p>For the training session, most computation lies in computing gradient, notably matrix multiplication, which will take incredibly long time when the model size scales up. We can handle this amount of computation on a few datasets, but it’ll be too much when there are many datasets to fine tune on.</p> <h2 id="lora">LoRA</h2> <p><a href="https://arxiv.org/abs/2106.09685" rel="external nofollow noopener" target="_blank">LoRA</a> solves this problems by assuming that the ‘change in weights during model adaptation also has a low “intrinsic rank”’, meaning that the updated parameter can be expressed as the multiplication of 2 low rank matrix. “Rank” is a term in Linear Algebra, which is equivalent to new information. Higher the rank the matrix has, more information the matrix contains.</p> <p>The update formula in LoRA is written as follow:</p> \[W = W_0 + AB \ \ where \ \ A\in R^{m\times r} \ \ and \ \ B\in R^{r\times n}. \ \ Here \ \ r\ll m \ \ and \ \ n\] <p>This way, the computation for gradient will be greatly reduced. For instance, suppose the weight matrix \(W\) is 768 by 1024 matrix. When we calculate the gradient for this matrix, we need to compute 768 \(\times\) 1024 parameters. For \(A\) and \(B\) matrix, we can let A be a 768 by 32 matrix and B be a 32 by 1024 matrix. When the model is doing gradient descent, we froze the model’s parameter, so the gradient for the \(W\) is 0. We only need to calculate gradient for \(A\) and \(B\), which has much less parameters than \(W\). Thus, the computation cost reduces significantly.</p> <h2 id="relora">ReLoRA</h2> <p>Currently, LoRA and its variants, QLoRA, MLoRA, etc, focus on fine-tuning models that are fully trained on datasets. Although during the fine-tuning stage, they require less computations, when we take previously fully trained model into account, it still takes quite a lot of computations. Can we apply LoRA as a training method to a model instead of fully training?</p> <p>When we look at the equation in LoRA closely, we can move \(W_0\) to the left and obtain:</p> \[\Delta W = AB \ \ where \ \ \Delta W = W - W_0\] <p>In a way, we can treat the \(AB\) as the gradient of the model, and yes, we can use LoRA to train a model. This idea is explored by ReLoRA.</p> <p>In their paper, they use LoRA as gradient to update model parameter. First, they train the model just like LoRA without updating model’s parameters. After 2000 steps, the matrix A and B will multiply and add to the model’s weight. Then both matrix will be reinitialize and get trained again.</p> <p>There are several advantage of this method. Firstly, this is much more parameter-efficient than fully-trained model. Secondly, according to the paper, ReLoRA outperforms LoRA though still can’t compare with fully trained model. Thus, the idea of using low-rank update for high rank matrix does work.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/35001724304205_.pic.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="conclusion">Conclusion</h2> <p>LoRA is one of the most popular PEFT method for its simplicity and effectiveness. From my intuition, the way LoRA update parameters is similar to how human learns new things. We often uses previous knowledge and updates the knowledge with some adjustment. For instance, we draw inspiration from real numbers and apply the same arithmetic operations on imaginary number with additional rule that \(i \times i = -1\). I believe LoRA is possibly the key component towards continual learning, making the model more knowledgable about the world and therefore, become the world model.</p> </div> </article> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"kasjfksj/kasjfksj.github.io","data-repo-id":"R_kgDOMlIRVQ","data-category":"Announcements","data-category-id":"DIC_kwDOMlIRVc4Ch8ft","data-mapping":"pathname","data-strict":"0","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Xiaoyang Li. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/tabs.min.js?b8748955e1076bbe0dabcf28f2549fdc"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"projects",description:"A growing collection of your cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-people",title:"people",description:"members of the lab or group",section:"Navigation",handler:()=>{window.location.href="/people/"}},{id:"post-diffusion-drifting-from-score-point-of-view",title:"Diffusion Drifting - from score point of view",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/drifting/"}},{id:"post-diffusion-models-for-image-compression-and-transmission",title:"Diffusion Models for Image Compression and Transmission",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/compression/"}},{id:"post-frequency-analysis-in-images-and-diffusion-models",title:"Frequency Analysis in Images and Diffusion Models",description:"Exploring how low- and high-frequency components reveal image structure and how diffusion models progressively build details.",section:"Posts",handler:()=>{window.location.href="/blog/2026/freq/"}},{id:"post-diffusion-series-video-diffusion-for-dmlab-maze-navigation",title:"Diffusion Series - Video Diffusion for DMLab Maze Navigation",description:"Comparing reconstruction-guided sampling and direct noised-frame injection for improving temporal consistency in long video generation",section:"Posts",handler:()=>{window.location.href="/blog/2026/video-guidance/"}},{id:"post-improving-zod-mc",title:"Improving ZOD-MC",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/zod/"}},{id:"post-diffusion-series-ddpm-model",title:"Diffusion Series - DDPM model",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/diffusion/"}},{id:"post-uiuc-summer-research-from-accidental-discord-find-to-lab-assistant",title:"UIUC Summer Research From Accidental Discord Find to Lab Assistant",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/UIUC-summer/"}},{id:"post-ito-39-s-integral",title:"Ito&#39;s Integral",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/Ito/"}},{id:"post-sde",title:"SDE",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/SDE/"}},{id:"post-grokking-a-possible-way-to-achieve-agi",title:"Grokking - a possible way to achieve AGI",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/Analysis-Grokfast/"}},{id:"post-grokking-a-possible-way-to-achieve-agi",title:"Grokking - a possible way to achieve AGI",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/Grokking/"}},{id:"post-history-of-position-encoding",title:"History of Position Encoding",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/position-encoding/"}},{id:"post-lora-a-potential-parameter-efficient-fine-tuning-method-for-large-models",title:"LoRA - a potential parameter efficient fine-tuning method for large models",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/LoRAa/"}},{id:"post-summer-class-experience",title:"Summer class experience",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/UCB-summer/"}},{id:"projects-video-diffusion",title:"Video diffusion",description:"",section:"Projects",handler:()=>{window.location.href="/projects/video_diffusion/"}},{id:"projects-partial-zod-mc",title:"Partial zod mc",description:"",section:"Projects",handler:()=>{window.location.href="/projects/zod_mc/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%78%69%61%6F%6C%36%36@%75%63%69.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=qc6CJjYAAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>