<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Understanding Attention and Multi-Head Attention - From Basics to RoPE Optimization | Xiaoyang Li </title> <meta name="author" content="Xiaoyang Li"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kasjfksj.github.io/blog/2025/attention/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Xiaoyang</span> Li </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus Changed </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Understanding Attention and Multi-Head Attention - From Basics to RoPE Optimization</h1> <p class="post-meta"> Created in March 20, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/formatting"> <i class="fa-solid fa-hashtag fa-sm"></i> formatting</a>   <a href="/blog/tag/images"> <i class="fa-solid fa-hashtag fa-sm"></i> images</a>   ·   <a href="/blog/category/model"> <i class="fa-solid fa-tag fa-sm"></i> model</a>   <a href="/blog/category/architecture"> <i class="fa-solid fa-tag fa-sm"></i> architecture</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="intro">Intro</h1> <p>In recent years, Transformer models have achieved tremendous success in the field of Natural Language Processing (NLP), with the Attention mechanism being a core component. This article will delve into the principles of the Attention mechanism and its extension, Multi-Head Attention, while introducing an optimization method—Rotary Position Embedding (RoPE), which significantly improves model performance.</p> <h1 id="core-principles-of-the-attention-mechanism">Core Principles of the Attention Mechanism</h1> <p>The Attention mechanism was originally used to address long-range dependency issues in sequence-to-sequence (Seq2Seq) models. Its core idea is that, when generating each output, the model can “dynamically focus” on different parts of the input sequence rather than relying on fixed context.</p> <h2 id="scaled-dot-product-attention">Scaled Dot-Product Attention</h2> <p>In Transformers, Attention is formalized as Scaled Dot-Product Attention. Given query matrices (Query), key matrices (Key), and value matrices (Value), the computation process is as follows:</p> \[\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V\] <p>Where:<br> \(Q \in \mathbb{R}^{n \times d_k}\) :Query matrix,<br> \(K \in \mathbb{R}^{m \times d_k}\) :Key matrix, <br> \(V \in \mathbb{R}^{m \times d_v}\) :Value matrix, <br> \(d_k\) :Dimension of the key vector,<br> \(\sqrt{d_k}\) :Scaling factor to prevent excessively large dot product results.<br></p> <h2 id="dynamic-weight-allocation">Dynamic Weight Allocation</h2> <p>Attention calculates the similarity between queries and keys to generate a weight matrix, then performs weighted summation over the value matrix. This process can be decomposed into:</p> <p>Similarity Calculation: \(QK^T\) measures the match between queries and keys, Scaling and Normalization: Divide by \(\sqrt{d_k}\) and normalize using softmax. Weighted Summation : Apply the normalized weights to the value matrix \(V\) to generate the final output.</p> <h1 id="multi-head-attention-the-power-of-parallelization">Multi-Head Attention: The Power of Parallelization</h1> <p>To enhance the model’s expressive power, Transformers introduced Multi-Head Attention. Its core idea is to capture information from different subspaces through multiple independent Attention heads.</p> <h2 id="mathematical-form-of-multi-head-attention">Mathematical Form of Multi-Head Attention</h2> <p>Linear Transformation : For each head, map \(Q\), \(K\), \(V\) to different subspaces: \(Q_i = QW_i^Q, \quad K_i = KW_i^K, \quad V_i = VW_i^V\)</p> <p>Where<br> \(W_i^Q \in \mathbb{R}^{d_k \times d_k}\),<br> \(W_i^K \in \mathbb{R}^{d_k \times d_k}\),<br> \(W_i^V \in \mathbb{R}^{d_v \times d_v}\) are learnable weight matrices.<br></p> <p>Parallel Computation of Attention : Each head independently computes Attention:<br> \(\text{head}_i = \text{Attention}(Q_i, K_i, V_i)\)</p> <p>Concatenation and Output Transformation : Concatenate the outputs of all heads and apply a linear transformation:<br> \(\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, \dots, \text{head}_h)W^O\)</p> <p>Where:<br> \(W^O \in \mathbb{R}^{h \cdot d_v \times d_{\text{model}}}\): Output weight matrix,<br> \(h\): Number of heads.<br></p> <h2 id="why-use-multi-head">Why Use Multi-Head?</h2> <ol> <li>Multi-Perspective Modeling : Each head learns different feature patterns (e.g., syntax, semantics).</li> <li>Enhanced Robustness : Avoids overfitting noise with a single Attention head.</li> <li>Experimental Validation : In machine translation tasks, Multi-Head Attention reduces perplexity by approximately 20% compared to single-head Attention.</li> </ol> <h1 id="rotary-position-embedding-rope-revolutionizing-position-encoding">Rotary Position Embedding (RoPE): Revolutionizing Position Encoding</h1> <p>Traditional Transformers use absolute position encoding (e.g., sine functions) to introduce sequence order information, but modeling positional relationships in long sequences remains limited. RoPE incorporates positional information into Attention calculations via rotation matrices, significantly improving performance.</p> <h2 id="mathematical-definition-of-rope">Mathematical Definition of RoPE</h2> <p>For positions \(m\) and \(n\)，RoPE transforms query and key vectors using rotation matrices \(R_m\) and \(R_n\):</p> \[\boldsymbol{q}' = R_m\boldsymbol{q}, \quad \boldsymbol{k}' = R_n\boldsymbol{k}\] <p>Where the rotation matrix\(R(m)\) is defined as:</p> \[\mathbf{R}_t = \begin{pmatrix} \cos t\theta_1 &amp; -\sin t\theta_1 &amp; \cdots &amp; 0 \\ \sin t\theta_1 &amp; \cos t\theta_1 &amp; \cdots &amp; 0 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; 0 &amp; \cdots &amp; \cos t\theta_{d/2} &amp; -\sin t\theta_{d/2} \\ 0 &amp; 0 &amp; \cdots &amp; \sin t\theta_{d/2} &amp; \cos t\theta_{d/2} \end{pmatrix}\] <h2 id="physical-meaning-of-rope">Physical Meaning of RoPE</h2> <p>Relative Position Encoding: Rotation operations make Attention scores depend only on relative positions \(m - n\)</p> <p>Theoretical Guarantee : RoPE satisfies translational invariance for position encoding \(\mathbf{q}_m' \cdot \mathbf{k}_n' = f(m - n)\).</p> \[\mathbf{q}'_m \cdot \mathbf{k}'_n = \sum_{i=1}^{d/2} \left[ q_m^{(2i-1)}k_n^{(2i-1)} + q_m^{(2i)}k_n^{(2i)} \right]\cos((m-n)\theta_i) \\ + \left[ q_m^{(2i)}k_n^{(2i-1)} - q_m^{(2i-1)}k_n^{(2i)} \right]\sin((m-n)\theta_i)\] <h2 id="experimental-results">Experimental Results</h2> <p>Using RoPE, the language model’s perplexity dropped significantly from 144 to 97 (a reduction of 32.6%), especially effective in long-text generation tasks.</p> <h1 id="workflow-explanation">Workflow explanation</h1> <h2 id="parameter-initialization-deep-dive">Parameter Initialization Deep Dive</h2> <p>Firstly, we initialize our Q, K, V matrices and the matrix \(W_O\):</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># d_model is the dimension of word embedding 
</span><span class="n">self</span><span class="p">.</span><span class="n">qkv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="mf">0.01</span><span class="o">*</span><span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">((</span><span class="mi">3</span><span class="o">*</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)))</span>
<span class="n">self</span><span class="p">.</span><span class="n">wo</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="mf">0.01</span><span class="o">*</span><span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">((</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)))</span>
</code></pre></div></div> <p>Why Combined QKV Matrix instead of using separate 3 matrices?</p> <p>• Architectural Efficiency: This allows for single contiguous memory block and better hardware utilization • Implementation Insight: Common pattern in modern transformers (e.g., GPT-2) vs older separate projections (original Transformer paper)</p> <p>Dimension of Input:<br> • Input: (B, S, D) (Batch × Sequence × ModelDim)<br> • Projection: (3D, D) matrix transforms D → 3D features<br> • Output after x @ qkv.T: (B, S, 3D)<br> Initialization Scale:<br> • 0.01*randn keeps initial weights small to prevent large softmax gradients early in training<br> <br> <br></p> <ol> <li>QKV Projection &amp; Splitting</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">QKV</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">self</span><span class="p">.</span><span class="n">qkv</span><span class="p">.</span><span class="n">T</span>  <span class="c1"># (B, S, D) -&gt; (B, S, 3D)
</span><span class="n">Q</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">chunk</span><span class="p">(</span><span class="n">QKV</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Each with (B, S, D)
</span></code></pre></div></div> <p>Visualization: For D=512:<br> Input x: [Batch, SeqLen, 512]<br> QKV: [Batch, SeqLen, 1536] # 3×512<br> Split → [Batch, SeqLen, 512] each for Q/K/V<br> Design Choice: Single projection vs multiple:<br> • Pro: Reduces memory fragmentation<br> • Con: Limits flexibility in head-specific projections<br> <br></p> <ol> <li>Multi-Head Splitting Mechanics</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># H: the number of heads; d_h: dimension for each head
</span><span class="n">dh</span> <span class="o">=</span> <span class="n">D</span> <span class="o">//</span> <span class="n">self</span><span class="p">.</span><span class="n">n_heads</span>  <span class="c1"># Head dimension
</span><span class="n">q_heads</span> <span class="o">=</span> <span class="n">Q</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">dh</span><span class="p">).</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># (B, S, D) -&gt; (B, S, H, d_h) -&gt; (B, H, S, d_h)
</span>
</code></pre></div></div> <p>Example with Numbers:<br> • Let D=8, H=2 (heads) → dh=4<br> • Original Q: (2, 5, 8) (Batch=2, Seq=5)<br> • After view: (2, 5, 2, 4)<br> • Transpose: (2, 2, 5, 4) (Head dimension at position 1)<br> Why Transpose?<br> • Aligns dimensions for batch matrix multiply in attention:<br> o (B, H, S, dh) @ (B, H, dh, S) → (B, H, S, S)<br> Head Specialization:<br> • Each head processes dh-dimensional subspace (e.g., 512-dim → 64×8 heads)<br> • Enables capturing diverse linguistic features:<br> o Head 1: Subject-verb agreement<br> o Head 2: Pronoun references<br> o Head 3: Temporal relationships<br></p> <ol> <li>Attention Mask Construction <div class="language-python highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tril</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">S_full</span><span class="p">),</span> <span class="n">diagonal</span><span class="o">=</span><span class="n">past_length</span><span class="p">)</span>
<span class="n">sq_mask</span> <span class="o">=</span> <span class="n">mask</span> <span class="o">==</span> <span class="mi">1</span>  <span class="c1"># Convert to boolean
</span></code></pre></div> </div> </li> </ol> <p>Causal Mask Visualization (S=3):<br> [[1 0 0]<br> [1 1 0]<br> [1 1 1]]<br> • Prevents attending to future positions in autoregressive generation<br> • Why Not Full Masking? Preserves parallel computation during training<br> <br></p> <ol> <li>Scaled Dot-Product Attention Core <div class="language-python highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">scaled_dot_product_attention</span><span class="p">(</span>
 <span class="n">q_heads</span><span class="p">,</span> <span class="n">k_heads</span><span class="p">,</span> <span class="n">v_heads</span><span class="p">,</span>  <span class="c1"># Shapes: (B, H, S, dh)
</span> <span class="n">attn_mask</span><span class="o">=</span><span class="n">sq_mask</span>
<span class="p">)</span>
</code></pre></div> </div> </li> </ol> <p>Under the Hood:<br></p> <ol> <li>Score Calculation:<br> Scores=dhQKT<br> • Scaling prevents gradient saturation in softmax<br> </li> <li>Masked Softmax:<br> AttentionWeights=softmax(Scores+MaskBias)<br> • Where MaskBias = -∞ for masked positions<br> </li> <li> <p>Value Weighting:<br> Output=AttentionWeights⋅V<br> Optimization: Uses fused CUDA kernel for:<br> • Memory-efficient attention computation<br> • Automatic mixed-precision support<br></p> </li> <li>Output Projection &amp; Head Merging</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>  <span class="c1"># (B, S, H, dh) → (B, S, D)
</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">self</span><span class="p">.</span><span class="n">wo</span><span class="p">.</span><span class="n">T</span>  <span class="c1"># Final projection
</span></code></pre></div></div> <p>Dimension Restoration:<br> After attention: (B, H, S, dh)<br> Transpose → (B, S, H, dh)<br> Reshape → (B, S, H*dh) = (B, S, D)<br> Why Final Projection (wo)?<br></p> <ol> <li>Feature Integration: Combines information from all heads<br> </li> <li>Dimension Matching: Ensures output matches original d_model<br> </li> <li>Learnable Mixing: Allows model to emphasize important heads<br> <br> <div class="language-markdown highlighter-rouge"> <div class="highlight"><pre class="highlight"><code>Complete Dimension Flow Table
| Operation         | Input Shape       | Output Shape      | Key Notes               |
| :---------------- | :---------------: | ----------------: | :---------------------- |
| Input             | (B, S, D)         | -                 | Base embeddings         |
| QKV Projection    | (B, S, D)         | (B, S, 3D)        | Single matrix multiply  |
| Q/K/V Split       | (B, S, 3D)        | 3×(B, S, D)       | Chunk on last dim       |
| Head Splitting    | (B, S, D)         | (B, H, S, dh)     | View + transpose        |
| Attention         | 3×(B, H, S, dh)   | (B, H, S, dh)     | Masked softmax          |
| Head Merge        | (B, H, S, dh)     | (B, S, D)         | Transpose + reshape     |
| Output Projection | (B, S, D)         | (B, S, D)         | Final feature mixing    |
</code></pre></div> </div> <p><br></p> <h1 id="summary-and-outlook">Summary and Outlook</h1> <p>Attention : Captures sequence dependencies through dynamic weight allocation. Multi-Head : Parallelizes modeling of multi-dimensional features, increasing model capacity. RoPE : Innovates position encoding methods, significantly reducing perplexity. Future directions include:</p> </li> </ol> <p>More efficient position encoding methods (e.g., hybrid absolute/relative position encoding). Sparse acceleration of Attention computation (e.g., Longformer, BigBird).</p> <p>To Do: Add architecture diagrams showing: b) Multi-head attention’s parallel processing c) RoPE’s rotation matrix operations</p> <p>proof of translational invariance for position encoding</p> <p>add code to showcase procedure</p> <p>Add training optimization tips: Include real-world impact metrics</p> </div> </article> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Xiaoyang Li. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/tabs.min.js?b8748955e1076bbe0dabcf28f2549fdc"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"A growing collection of your cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-repositories",title:"repositories",description:"Edit the `_data/repositories.yml` and change the `github_users` and `github_repos` lists to include your own GitHub profile and repositories.",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-cv",title:"cv",description:"This is a description of the page. You can modify it in '_pages/cv.md'. You can also change or remove the top pdf download button.",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-teaching",title:"teaching",description:"Materials for courses you taught. Replace this text with your description.",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"nav-people",title:"people",description:"members of the lab or group",section:"Navigation",handler:()=>{window.location.href="/people/"}},{id:"dropdown-publications",title:"publications",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-projects",title:"projects",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-blog",title:"blog",description:"",section:"Dropdown",handler:()=>{window.location.href="/blog/"}},{id:"post-uiuc-summer-research-from-accidental-discord-find-to-lab-assistant",title:"UIUC Summer Research From Accidental Discord Find to Lab Assistant",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/UIUC-summer/"}},{id:"post-understanding-attention-and-multi-head-attention-from-basics-to-rope-optimization",title:"Understanding Attention and Multi-Head Attention - From Basics to RoPE Optimization",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/attention/"}},{id:"post-grokking-a-possible-way-to-achieve-agi",title:"Grokking - a possible way to achieve AGI",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/Analysis-Grokfast/"}},{id:"post-grokking-a-possible-way-to-achieve-agi",title:"Grokking - a possible way to achieve AGI",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/Grokking/"}},{id:"post-history-of-position-encoding",title:"History of Position Encoding",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/position-encoding/"}},{id:"post-lora-a-potential-parameter-efficient-fine-tuning-method-for-large-models",title:"LoRA - a potential parameter efficient fine-tuning method for large models",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/LoRAa/"}},{id:"post-summer-class-experience",title:"Summer class experience",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/UCB-summer/"}},{id:"post-image-construction-experiment",title:"Image construction experiment",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/VAE/"}},{id:"post-diffusion-model",title:"Diffusion model",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/diffusion/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%78%69%61%6F%6C%36%36@%75%63%69.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=qc6CJjYAAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>